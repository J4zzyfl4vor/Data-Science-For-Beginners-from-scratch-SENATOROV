"""2.1. Модель вычислений RAM."""

# Разработка машинно-независимых алгоритмов основывается на гипотетическом компьютере,
# называемом машиной с произвольным доступом к памяти (Raпdom Access
# Machiпe), или RАМ-машиной. Согласно этой модели наш компьютер работает таким
# образом: ·
# + для исполнения любой простой операции ( +, *, -, =, if, call) требуется ровно один
# временной шаг;
# + циклы и подпрограммы не считаются простыми операциями, а состоят из нескольких
# простых операций. Нет смысла считать подпрограмму сортировки одношаговой
# операцией, поскольку для сортировки 1 ООО ООО элементов потребуется определенно
# намного больше времени, чем для сортировки десяти элементов. Время исполнения
# цикла или подпрограммы зависит от количества итераций или специфического характера
# подпрограммы;
# + каждое обращение к памяти занимает один временной шаг. Кроме этого, наш компьютер
# обладает неограниченным объемом оперативной памяти. Кэш и диск в модели
# RAM не применяются.
# Время исполнения алгоритма в RАМ-модели вычисляется по общему количеству шагов,
# требуемых алгоритму для решения того или иного экземпляра задачи. Допуская,
# что наша RАМ-машина исполняет определенное количество шагов/операций за секунду,
# количество шагов легко перевести в единицы времени.

# Алгоритмы можно изучать и анализировать, не прибегая к использованию конкретного
# языка программирования или компьютерной платформы.

# Чтобы понять, что означает наилучший, наихудший и средний случай сложности алгоритма
# (т. е. время его исполнения в соответствующем случае), нужно рассмотреть исполнение
# алгоритма на всех возможных экземплярах входных данных. В случае задачи
# сортировки множество входных экземпляров состоит из всех п возможных компоновок
# ключей для всех возможных значений п. Каждый входной экземпляр можно представить
# в виде точки графика (рис. 2.1), где ось х представляет размер входа задачи (для
# сортировки это будет количество элементов, подлежащих сортировке), а ось у- количество
# шагов, требуемых алгоритму для обработки такого входного экземпляра.

# ***Сложность алгоритмов***
#
# сложность алгоритма в наихудшем случае - это функция, определяемая максимальным
# количеством шагов, требуемых для обработки любого входного экземпляра
# размером n. Этот случай отображается кривой, проходящей через самую высшую
# точку каждого столбца;
# + сложность алгоритма в наихучшем случае - это функция, определяемая минимальным
# количеством шагов, требуемых для обработки Любого входного экземпляра
# размером n. Этот случай отображается кривой, проходящей через самую низшую
# точку каждого столбца;
# + сложность алгоритма в среднем случае, или его ожидаемое время, - это функция,
# определяемая средним количеством шагов, требуемых для обработки всех экземпляров
# размером n.

# Каждая из этих временных сложностей определяет числовую функцию для любого алгоритма,
# соотносящую время исполнения с размером задачи. Эти функции определены так
# же строго, как и любые другие числовые функции, будь то уравнение у= х2
# - 2х + 1 или
# цена акций компании Alphabet в зависимости от времени. Но функции временной сложности
# настолько трудны для понимания, что, прежде чем приступать к их анализу, их
# нужно упростить, используя для этого асимптотическую нотацию - обозначение «Big
# Oh» («О-большое»).

# 2.2. Асимптотические («Big Oh») обозначения
#
#
# Временную сложность наилучшего, наихудшего и среднего случаев для любого алгоритма
# можно представить как числовую функцию от размеров возможных экземпляров
# задачи. Но работать с этими функциями очень трудно, поскольку они обладают следующими
# свойствами:
# • являются слишком волнистыми.
# Время исполнения алгоритма, например, двоичного поиска, обычно меньше для
# массивов, имеющих размер п = i - 1, где k- целое число. Эта особенность не имеет
# большого значения, но служит предупреждением, что точная функция временной
# сложности любого алгоритма вполне может иметь неровный график с большим
# количеством небольших выпуклостей и впадин
# + требуют слишком много информации для точного определения.
# Чтобы подсчитать точное количество инструкций RАМ-машины, исполняемых
# в худшем случае, нужно, чтобы алгоритм был расписан в подробностях полной
# компьютерной программы. Более того, точность ответа зависит от маловажных деталей
# кодировки (например, был ли употреблен в коде оператор case вместо вложенных
# операторов н). Точный анализ наихудшего случая - например, такого:
# Т(п) = 12 754п 2 + 4353п + 8341g2п + 13 546,
# очевидно, был бы очень трудной задачей, решение которой не предоставляет нам
# никакой дополнительной информации, кроме той, что «с увеличением п временная
# сложность возрастает квадратически».

# Формальные определения, связанные с асимптотическими обозначениями, выглядят
# таким образом:
# + f{п) = О(g(п)) означает, что функция.f{п) ограничена сверху функцией с· g(п). Иными
# словами, существует такая константа с, при которой.f{п) :::=с· g(п) для каждого
# достаточно большого значения п (т. е. для всех п ~ п0 для некоторой константы п0 ).
# Этот случай показан на рис. 2.3, а;
# + j{п) = Q(g(п)) означает, что функция.f{п) ограничена снизу функцией с · g(п). Иными
# словами, существует такая константа с, для которой .f{п) ~ с· g(п) для всех п ~ п0 •
# Этот случай показан на рис. 2.3, 6;

# Анализ наихудшего случая и асимптотические обозначения являются инструментами,
# которые существенно упрощают задачу сравнения эффективности алгоритмов.

# процесс базового анализа алгоритмов обычно порождает лишь небольшое
# количество классов функций, достаточное для покрытия почти всех алгоритмов, рассматриваемых
# в этой книге. Далее приводятся эти классы в порядке возрастания доминирования.
# + Функции-константы,f{п) = 1.
# Такие функции могут измерять трудоемкость сложения двух чисел, распечатывания
# текста государственного гимна или рост таких функций, как .f{n) = min(n, 100). По
# большому счету зависимость от параметра п отсутствует.
# + Логарифмические функции,f{п) = log п.
# Логарифмическая временная сложность проявляется в таких алгоритмах, как двоичный
# поиск. С увеличением п эти функции возрастают довольно медленно, но быстрее,
# чем функции-константы (которые вообще не возрастают). Логарифмы рассматриваются
# более подробно в разд. 2. 7.
# + Линейные функции,f(п) = п.
# Такие функции измеряют трудоемкость просмотра каждого элемента в массиве
# элементов один раз (или два раза, или десять раз)- например, для определения
# наибольшего или наименьшего элемента или для вычисления среднего значения.
# + Суперлинейные функции,f(п) = п lg п.
# Этот важный класс функций возникает в таких алгоритмах, как quicksort и merge-
# sort. Эти функции возрастают лишь немного быстрее, чем линейные (см. табл. 2.1 ),
# но достаточно быстро, чтобы подняться к более высокому классу доминирования.
# + Квадратичные функции,f{п) =
# п2 .
# Эти функции измеряют трудоемкость просмотра большинства или всех пар элементов
# в универсальном множестве из п элементов. Они возникают в таких алгоритмах,
# как сортировка вставками или сортировка методом выбора.
# + Кубические функцuи,f(п) =
# п3 .
